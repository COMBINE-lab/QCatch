{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"QCatch","text":"<p>QCatch: Quality Control downstream of <code>alevin-fry</code> and <code>simpleaf</code></p> <p>View the complete QCatch documentation with interactive examples, FAQs, and detailed usage guides.</p>"},{"location":"#installation","title":"Installation","text":"<p>You need to have Python 3.11 or 3.12 installed on your system.</p> <p>There are several alternative options to install QCatch:</p>"},{"location":"#1-bioconda","title":"1. Bioconda","text":"<p>You can install using Conda from Bioconda.</p> <pre><code>conda install -c bioconda qcatch\n</code></pre>"},{"location":"#2-pypi","title":"2. PyPI","text":"<p>You can also install from PyPI using <code>pip</code>:</p> <pre><code>pip install qcatch\n</code></pre> <p>Tips: If you run into environment issues, you can also use the provided Conda .yml file, which specifies the exact versions of all dependencies to ensure consistency.</p> <pre><code>conda env create -f qcatch_conda_env.yml\n</code></pre>"},{"location":"#basic-usage","title":"Basic Usage","text":"<p>Provide the path to the parent folder for quantification results, or the direct path to a .h5ad file generated by <code>alevin-fry</code> or <code>simpleaf</code>. QCatch will automatically scan the input path, assess data quality, and generate an interactive HTML report that can be viewed directly in your browser.</p> <pre><code>qcatch \\\n    --input path/to/your/quantification/result \\\n    --output path/to/desired/QC/output/folder \\ # if you want another folder for output\n    --chemistry 10X_3p_v3\n    --save_filtered_h5ad\n\n</code></pre>"},{"location":"#tutorial-run-qcatch-on-example-data","title":"Tutorial: Run QCatch on Example data","text":""},{"location":"#step-1-download-dataset","title":"Step 1 \u2014 Download Dataset","text":"<pre><code>#!/bin/bash\nset -e  # Exit immediately if a command exits with a non-zero status\n\necho \"\ud83d\udce6 Downloading QCatch example dataset...\"\n\n# Define where to run the tutorial (you can change this path if desired)\nCWD=$(pwd)  # Current working directory\nTUTORIAL_DIR=\"${CWD}/qcatch_tutorial\"\n\n# Clean any existing tutorial directory to ensure a fresh download\nrm -rf \"$TUTORIAL_DIR\" &amp;&amp; mkdir -p \"$TUTORIAL_DIR\"\nZIP_FILE=\"data.zip\"\n\n# Download from Box\nwget -O \"$ZIP_FILE\" \"https://umd.box.com/shared/static/zd4sai70uw9fs24e1qx6r41ec50pf45g.zip?dl=1\"\n\n# Unzip and clean up\nunzip \"$ZIP_FILE\" -d \"$TUTORIAL_DIR\"\nrm \"$ZIP_FILE\"\n\necho \"\u2705 Test data downloaded to $TUTORIAL_DIR\"\n</code></pre>"},{"location":"#step-2-run-the-qcatch","title":"Step 2 - Run the qcatch","text":"<p>\ud83c\udf89 All set! Now let\u2019s run QCatch:</p> <pre><code>#Set up output directory\nOUT_DIR=\"${TUTORIAL_DIR}/output\"\nmkdir -p \"$OUT_DIR\"\n\n# Step2 - Run QCatch\nqcatch --input ${TUTORIAL_DIR}/test_data/simpleaf_with_map/quants.h5ad \\\n       --output ${OUT_DIR} \\\n       --chemistry 10X_3p_v3\n</code></pre>"},{"location":"#tips","title":"Tips","text":"<p>1- Input path:</p> <p>Provide either:</p> <ul> <li>the path to the parent directory containing quantification results, or</li> <li>the direct path to a .h5ad file generated by those tools.</li> </ul> <p>QCatch will automatically detect the input type: - If a .h5ad file is provided, QCatch will process it directly. - If a directory is provided, QCatch will first look for an existing .h5ad file inside. If not found, it will fall back to processing the mtx-based quantification results.</p> <p>See the example directory structures at the end of the Tips section for reference:</p> <p>2- Output path:</p> <p>If you do not want any modifications in your input folder/files, speaficy the output path, we will save any new results and QC HTML report there.</p> <p>By default, QCatch saves the QC report and all output files in your input directory. Therefore, specifying an output path is optional. Specifically, - If QCatch finds the <code>.h5ad</code> file from input path, it will modify the original <code>.h5ad</code> file in place by appending cell filtering results to <code>anndata.obs</code> and create a separate QC report in HTML in the input folder. - For <code>mtx-based</code> results, QCatch will generate text files for the cell calling reuslts as well as the QC report in the input folder.\"</p> <p>3- Chemistry:</p> <p>We highly recommend specifying the chemistry used in your experiment. By default, QCatch will assume the settings for 10X 3' v2 and v3 chemistry. If you use custom chemistry that not listed in the predefined chemistry options. You can specify the <code>--n_partitions</code>.</p> <p>3- Gene gene mapping file:</p> <p>If you are using simpleaf v0.19.3 or later, the generated .h5ad file already includes gene names. In this case, you do not need to specify the --gene_id2name_file option.</p> <p>To provide a 'gene id to name mapping' info, the file should be a TSV containing two columns\u2014\u2018gene_id\u2019 (e.g., ENSG00000284733) and \u2018gene_name\u2019 (e.g., OR4F29)\u2014 without header row. If not provided, the program will attempt to retrieve the mapping from a remote registry. If that lookup fails, mitochondria plots will not be displayed, but will not affect the QC report.</p> <p>4- Save filtered h5ad file:</p> <p>If you want to save filtered h5ad file separately, you can specify <code>--save_filtered_h5ad</code>, which is only applicable when QCatch detects the h5ad file as the input.</p> <p>5- Specify your desired cell list:</p> <p>If you want to use a specified list of valid cell barcodes, you can provide the file path with <code>--valid_cell_list</code>. QCatch will then skip the default cell calling step and use the supplied list instead. The updated .h5ad file will include only one additional column, 'is_retained_cells', containing boolean values based on the specified list.</p> <p>6- Skip clustering plots:</p> <p>To reduce runtime, you may enable the <code>--skip_umap_tsne</code> option to bypass dimensionality reduction and visualization steps.</p> <p>7- Export the summary metrics</p> <p>To export the summary metrics, enable the <code>--export_summary_table</code> flag. The summary table will be saved as a separate CSV file in the output directory.</p> <p>8- Debug-level message</p> <p>To get debug-level messages and more intermediate computation in cell calling step, you can specify <code>--verbose</code></p> <p>9- Re-run QCatch on modified h5ad file If you re-run QCatch analysis on a modified <code>.h5ad</code> file (i.e., an <code>.h5ad</code> file with additional columns added for cell calling results), the existing cell calling-related columns will be removed and then replaced with new results. The new cell calling can be generated either through QCatch's internal method or based on a user-specified list of valid cell barcodes.</p> <p>Example directory structures:</p> <pre><code># simpleaf\nparent_quant_dir/\n\u251c\u2500\u2500 af_map/\n\u251c\u2500\u2500 af_quant/\n\u2502   \u251c\u2500\u2500 alevin/\n\u2502   \u2502   \u251c\u2500\u2500 quants_mat_cols.txt\n\u2502   \u2502   \u251c\u2500\u2500 quants_mat_rows.txt\n\u2502   \u2502   \u251c\u2500\u2500 quants_mat.mtx\n\u2502   \u2502   \u2514\u2500\u2500 quants.h5ad (available if you use simpleaf after v0.19.3)\n\u2502   \u2502   ...\n\u2502   \u251c\u2500\u2500 featureDump.txt\n\u2502   \u2514\u2500\u2500 quant.json\n\u2514\u2500\u2500 simpleaf_quant_log.json\n\n# alevin-fry\nparent_quant_dir/\n\u251c\u2500\u2500 alevin/\n\u2502   \u251c\u2500\u2500 quants_mat_cols.txt\n\u2502   \u251c\u2500\u2500 quants_mat_rows.txt\n\u2502   \u2514\u2500\u2500 quants_mat.mtx\n\u251c\u2500\u2500 featureDump.txt\n\u2514\u2500\u2500 quant.json\n\n</code></pre> <p>For more advanced options and usage details, see the sections below.</p>"},{"location":"#command-line-arguments","title":"Command-Line Arguments","text":"Flag Short Type Description <code>--input</code> <code>-i</code> <code>str</code> (Required) Path to the input directory containing the quantification output files or to the HDF5 file itself. <code>--output</code> <code>-o</code> <code>str</code>(Required) Path to the output directory. <code>--chemistry</code> <code>-c</code> <code>str</code>(Optional but recommend) Specifies the chemistry used in the experiment, determining the range for the <code>empty_drops</code> step. Options: <code>'10X_3p_v2'</code>, <code>'10X_3p_v3'</code>, <code>'10X_3p_v4'</code>, <code>'10X_3p_LT'</code>,<code>'10X_5p_v3'</code>,<code>'10X_HT'</code>. Default: Will use the range for <code>'10X_3p_v2'</code> and <code>'10X_3p_v3'</code>. <code>--save_filtered_h5ad</code> <code>-s</code> <code>flag</code> (Optional) If enabled, <code>qcatch</code> will save a separate <code>.h5ad</code> file containing only the retained cells. <code>--gene_id2name_file</code> <code>-g</code> <code>str</code> (Optional) File provides a mapping from gene IDs to gene names. The file must be a TSV containing two columns\u2014\u2018gene_id\u2019 (e.g., ENSG00000284733) and \u2018gene_name\u2019 (e.g., OR4F29)\u2014without a header row. If not provided, the program will attempt to retrieve the mapping from a remote registry. If that lookup fails, mitochondria plots will not be displayed. <code>--valid_cell_list</code> <code>-l</code> <code>str</code> (Optional) File provides a user-specified list of valid cell barcode. The file must be a TSV containing one column with cell barcodes without a header row. If provided, qcatch will skip the internal cell calling steps and and use the supplied list instead <code>--n_partitions</code> <code>-n</code> <code>int</code> (Optional) Number of partitions (max number of barcodes to consider for ambient estimation). Skip this step if you already specified <code>--chemistry</code>. Only use <code>--n_partitions</code> when your experiment uses a custom chemistry not listed in the predefined chemistry options. <code>--skip_umap_tsne</code> <code>-u</code> <code>flag</code> (Optional) If provided, skips generation of UMAP and t-SNE plots. <code>--export_summary_table</code> <code>-x</code> <code>flag</code> (Optional) If enabled, QCatch will export the summary metrics as a separate CSV file. <code>--verbose</code> <code>-b</code> <code>flag</code> (Optional) Enable verbose logging with debug-level messages. <code>--version</code> <code>-v</code> <code>flag</code> (Optional) Display the installed version of qcatch."},{"location":"api/","title":"API","text":""},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#026-2025-06-29","title":"[0.2.6] 2025-06-29","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Updated QCatch documentation and included an interactive demo page</li> <li>Add tutorial scripts in the README.</li> <li>Transitioned to uv for building and package management and relaxed dependencies for compatibility.</li> </ul>"},{"location":"changelog/#025-2025-05-19","title":"[0.2.5] 2025-05-19","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Adopted Cookiecutter-style structure based on the Scanpy project template.</li> <li>Added a new flag to export summary metrics as a CSV file.</li> <li>The HTML report now also includes a warning for low mapping rate.</li> <li>Added unit tests and scripts to download test data</li> <li>Updated the EmptyDrops step by removing the limitation on the number of candidate barcodes and making the FDR threshold dynamically adjustable based on the chemistry version.</li> <li>Added source code snippets to the help text section of clustering plots</li> </ul>"},{"location":"changelog/#changed","title":"Changed","text":"<ul> <li>Switched to more concise progress logging during the cell-calling step.</li> </ul>"},{"location":"contributing/","title":"Contributing guide","text":"<p>Scanpy provides extensive developer documentation, most of which applies to this project, too. This document will not reproduce the entire content from there. Instead, it aims at summarizing the most important information to get you started on contributing.</p> <p>We assume that you are already familiar with git and with making pull requests on GitHub. If not, please refer to the scanpy developer guide.</p>"},{"location":"contributing/#installing-dev-dependencies","title":"Installing dev dependencies","text":"<p>In addition to the packages needed to use this package, you need additional python packages to run tests and build the documentation.</p> <p>:::::{tabs} ::::{group-tab} Hatch The easiest way is to get familiar with hatch environments, with which these tasks are simply:</p> <pre><code>hatch test  # defined in the table [tool.hatch.envs.hatch-test] in pyproject.toml\nhatch run docs:build  # defined in the table [tool.hatch.envs.docs]\n</code></pre> <p>::::</p> <p>::::{group-tab} Pip If you prefer managing environments manually, you can use <code>pip</code>:</p> <pre><code>cd QCatch\npython3 -m venv .venv\nsource .venv/bin/activate\npip install -e \".[dev,test,doc]\"\n</code></pre> <p>:::: :::::</p>"},{"location":"contributing/#code-style","title":"Code-style","text":"<p>This package uses pre-commit to enforce consistent code-styles. On every commit, pre-commit checks will either automatically fix issues with the code, or raise an error message.</p> <p>To enable pre-commit locally, simply run</p> <pre><code>pre-commit install\n</code></pre> <p>in the root of the repository. Pre-commit will automatically download all dependencies when it is run for the first time.</p> <p>Alternatively, you can rely on the pre-commit.ci service enabled on GitHub. If you didn't run <code>pre-commit</code> before pushing changes to GitHub it will automatically commit fixes to your pull request, or show an error message.</p> <p>If pre-commit.ci added a commit on a branch you still have been working on locally, simply use</p> <pre><code>git pull --rebase\n</code></pre> <p>to integrate the changes into yours. While the pre-commit.ci is useful, we strongly encourage installing and running pre-commit locally first to understand its usage.</p> <p>Finally, most editors have an autoformat on save feature. Consider enabling this option for ruff and biome.</p> <p>(writing-tests)=</p>"},{"location":"contributing/#writing-tests","title":"Writing tests","text":"<p>This package uses pytest for automated testing. Please write {doc}<code>scanpy:dev/testing</code> for every function added to the package.</p> <p>Most IDEs integrate with pytest and provide a GUI to run tests. Just point yours to one of the environments returned by</p> <pre><code>hatch env create hatch-test  # create test environments for all supported versions\nhatch env find hatch-test  # list all possible test environment paths\n</code></pre> <p>Alternatively, you can run all tests from the command line by executing</p> <p>:::::{tabs} ::::{group-tab} Hatch</p> <pre><code>hatch test  # test with the highest supported Python version\n# or\nhatch test --all  # test with all supported Python versions\n</code></pre> <p>::::</p> <p>::::{group-tab} Pip</p> <pre><code>source .venv/bin/activate\npytest\n</code></pre> <p>:::: :::::</p> <p>in the root of the repository.</p>"},{"location":"contributing/#continuous-integration","title":"Continuous integration","text":"<p>Continuous integration will automatically run the tests on all pull requests and test against the minimum and maximum supported Python version.</p> <p>Additionally, there's a CI job that tests against pre-releases of all dependencies (if there are any). The purpose of this check is to detect incompatibilities of new package versions early on and gives you time to fix the issue or reach out to the developers of the dependency before the package is released to a wider audience.</p>"},{"location":"contributing/#publishing-a-release","title":"Publishing a release","text":""},{"location":"contributing/#updating-the-version-number","title":"Updating the version number","text":"<p>Before making a release, you need to update the version number in the <code>pyproject.toml</code> file. Please adhere to Semantic Versioning, in brief</p> <p>Given a version number MAJOR.MINOR.PATCH, increment the:</p> <ol> <li>MAJOR version when you make incompatible API changes,</li> <li>MINOR version when you add functionality in a backwards compatible manner, and</li> <li>PATCH version when you make backwards compatible bug fixes.</li> </ol> <p>Additional labels for pre-release and build metadata are available as extensions to the MAJOR.MINOR.PATCH format.</p> <p>Once you are done, commit and push your changes and navigate to the \"Releases\" page of this project on GitHub. Specify <code>vX.X.X</code> as a tag name and create a release. For more information, see managing GitHub releases. This will automatically create a git tag and trigger a Github workflow that creates a release on PyPI.</p>"},{"location":"contributing/#writing-documentation","title":"Writing documentation","text":"<p>Please write documentation for new or changed features and use-cases. This project uses sphinx with the following features:</p> <ul> <li>The myst extension allows to write documentation in markdown/Markedly Structured Text</li> <li>Numpy-style docstrings (through the napoloen extension).</li> <li>Jupyter notebooks as tutorials through myst-nb (See Tutorials with myst-nb)</li> <li>sphinx-autodoc-typehints, to automatically reference annotated input and output types</li> <li>Citations (like {cite:p}<code>Virshup_2023</code>) can be included with sphinxcontrib-bibtex</li> </ul> <p>See scanpy\u2019s {doc}<code>scanpy:dev/documentation</code> for more information on how to write your own.</p>"},{"location":"contributing/#tutorials-with-myst-nb-and-jupyter-notebooks","title":"Tutorials with myst-nb and jupyter notebooks","text":"<p>The documentation is set-up to render jupyter notebooks stored in the <code>docs/notebooks</code> directory using myst-nb. Currently, only notebooks in <code>.ipynb</code> format are supported that will be included with both their input and output cells. It is your responsibility to update and re-run the notebook whenever necessary.</p> <p>If you are interested in automatically running notebooks as part of the continuous integration, please check out this feature request in the <code>cookiecutter-scverse</code> repository.</p>"},{"location":"contributing/#hints","title":"Hints","text":"<ul> <li>If you refer to objects from other packages, please add an entry to <code>intersphinx_mapping</code> in <code>docs/conf.py</code>.   Only if you do so can sphinx automatically create a link to the external documentation.</li> <li>If building the documentation fails because of a missing link that is outside your control,   you can add an entry to the <code>nitpick_ignore</code> list in <code>docs/conf.py</code></li> </ul> <p>(docs-building)=</p>"},{"location":"contributing/#building-the-docs-locally","title":"Building the docs locally","text":"<p>:::::{tabs} ::::{group-tab} Hatch</p> <pre><code>hatch run docs:build\nhatch run docs:open\n</code></pre> <p>::::</p> <p>::::{group-tab} Pip</p> <pre><code>source .venv/bin/activate\ncd docs\nsphinx-build -M html . _build -W\n(xdg-)open _build/html/index.html\n</code></pre> <p>:::: :::::</p>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#documentation-for-featuredump-column-names-in-anndataobs","title":"\ud83e\udd50 Documentation for FeatureDump/ Column names in Anndata.obs","text":"Term Description CB Cell Barcode Corrected Reads The total number of corrected reads, including both mapped and unmapped reads. Mapped Reads The number of reads that were successfully mapped to the reference. Deduplicated Reads The number of deduplicated reads, processed by UMI deduplication. Mapping Rate The ratio of mapped reads to corrected reads. Deduplication Rate The ratio of deduplicated reads to mapped reads. Mean by Max Calculated as mean_expr / max_umi, where:mean_expr is the total UMI count divided by the number of genes with non-zero expression levels.max_umi is the maximum expression level across all genes. Number of Genes Expressed The number of genes expressed in this cell. Number of Genes Above Mean The number of genes with expression levels above the mean_expr, where mean_expr is defined as the total UMI count divided by the number of genes with non-zero expression levels."},{"location":"faq/#summary-metric","title":"\ud83e\udd5d Summary metric","text":"Value showed in summary table Description Number of retained cells The number of valid and high quality cells that passed the cell calling step. This includes cells identified during the initial filtering and additional cells identified by the EmptyDrops step, whose expression profiles are significantly distinct from the ambient background. Number of all processed cells The total number of cell barcodes observed in the processed sample. Cells with zero reads have been excluded. Mean reads per retained cell The total number of reads assigned to the retained cells, including the mapped and unmapped reads, divided by the number of retained cells. Median UMI per retained cell The median number of deduplicated reads (UMIs) per retained cell. Median genes per retained cell The median number of genes detected per retained cell. Total genes detected for retained cells The total number of unique genes detected across all retained cells. Mapping rate Fraction of reads that mapped to the augmented reference, calculated as mapped reads / total processed reads. Sequencing saturation Sequencing saturation measures the proportion of reads coming from already-seen UMIs, calculated as 1 - (deduplicated reads / total reads). High saturation suggests limited gain from additional sequencing, while low saturation indicates that further sequencing could reveal more unique molecules (UMIs)."},{"location":"faq/#3-plots","title":"\ud83c\udf70 3- Plots","text":""},{"location":"faq/#31-knee-plots","title":"3.1  Knee plots","text":"<p>We order the UMI count(deduplicated reads) for each cell and sort in descending order to get the cell rank, and use the scatter plot to display the UMI count against the cell rank. We also use the scatter plot to display the number of detected genes against the cell rank.</p>"},{"location":"faq/#32-umi-counts-and-detected-gene-across-cell-barcodes","title":"3.2 UMI Counts and Detected Gene Across Cell Barcodes","text":"<p>The barcode frequency is calculated as the number of reads associated with each cell barcode.</p> <p>The first two plots show barcode frequency against two key metrics: the number of UMIs and the number of detected genes per barcode. The third plot illustrates how the number of detected genes increases with UMI count per cell.</p>"},{"location":"faq/#33-umi-deduplication-plot","title":"3.3 UMI Deduplication plot","text":"<p>The scatter plot compares the number of mapped reads and number of UMIs for each retained cell. Each point represents a cell, with the x-axis showing the mapped reads count and the y-axis showing the deduplicated UMIs count. The reference line indicates the mean deduplication rate across all cells.</p> <p>UMI Deduplication: UMI deduplication is the process of identifying and removing duplicate reads that arise from PCR amplification of the same original molecule.</p> <p>Dedup Rate: The UMI count divided by the number of mapped reads for each cell.</p>"},{"location":"faq/#34-distribution-of-detected-gene-count-and-mitochondrial-percentage-plot","title":"3.4 Distribution of Detected Gene Count and Mitochondrial Percentage Plot","text":"<p>The plot depicts the distribution of detected gene counts per cell. The violin plot shows the distribution of mitochondrial gene expression percentages.</p> <p>Note: The \u201cAll Cells\u201d plot does not display every processed cell. To improve visualization and reduce clutter from very low-quality cells, we excluded cells with fewer than 20 detected genes\u2014these are typically considered nearly empty. In contrast, the \u201cRetained Cells\u201d plot includes all retained cells, without applying this gene count filter.</p>"},{"location":"faq/#35-bar-plot-for-sua-counts-and-splicing-ratio-distribution","title":"3.5 Bar Plot for S/U/A Counts and Splicing Ratio Distribution","text":"<p>When using \u201cUSA mode\u201d in alevin-fry, spliced (S), unspliced (U), and ambiguous (A) read counts are generated separately for each gene in each cell.</p> <p>In the bar plot, we first sum the spliced, unspliced, and ambiguous counts across all genes and all cells. The plot then displays the total number of reads in each splicing category: Spliced (S), Unspliced (U), and Ambiguous (A).</p> <p>In the histogram, we calculate the splicing ratio for each cell as (S + A) / (S + U + A), where the counts are summed across all genes. The histogram shows the distribution of these per-cell splicing ratios.</p>"},{"location":"faq/#36-clustering-umap-and-t-sne","title":"3.6 Clustering: UMAP and t-SNE","text":"<p>These plots represent low-dimensional projections of high-dimensional gene expression profiles. Each point corresponds to a single cell. Cells that are positioned close to one another in the plot are inferred to have similar transcriptomic signatures, suggesting similarity in cell type or state.</p> <p>Note: Only retained cells are included in these visualizations, and no additional filtering was applied beyond the cell retention step. Standard preprocessing was performed using Scanpy, including normalization, log transformation, highly variable gene selection, and dimensionality reduction.</p>"},{"location":"references/","title":"References","text":"<pre><code>:cited:\n</code></pre>"},{"location":"demo/demo/","title":"Demo","text":""},{"location":"demo/demo/#demo-report","title":"Demo report","text":"<p>In this demo, we applied QCatch to a publicly available dataset of human peripheral blood mononuclear cells (PBMCs), obtained from the 10X Genomics website.</p> <p>This dataset comprises scRNA-seq data from 1k PBMCs isolated from a healthy human donor, generated using the Chromium Single Cell 3' Gene Expression v3 chemistry.</p>"}]}